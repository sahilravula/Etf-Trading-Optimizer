{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJLZZpo74lAM",
        "outputId": "a1482fe6-617a-482c-bcc9-fe8aef50cab9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# ETF Trading Optimization Platform - Jupyter Notebook Version\n",
        "# Complete end-to-end system for ETF analysis, prediction, and portfolio optimization\n",
        "\n",
        "# Cell 1: Import all required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import sqlite3\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Data Collection and Storage Class\n",
        "class ETFDataManager:\n",
        "    def __init__(self, db_path='etf_data.db'):\n",
        "        self.db_path = db_path\n",
        "        self.connection = sqlite3.connect(db_path)\n",
        "        self.setup_database()\n",
        "\n",
        "        # Popular ETFs for analysis\n",
        "        self.etf_symbols = [\n",
        "            'SPY', 'QQQ', 'IWM', 'VTI', 'VOO', 'VXUS', 'VEA', 'VWO',\n",
        "            'BND', 'AGG', 'TLT', 'IEF', 'XLF', 'XLK', 'XLE', 'XLV',\n",
        "            'XLI', 'XLP', 'XLY', 'XLU', 'GLD', 'SLV', 'VNQ', 'EEM',\n",
        "            'EFA', 'IJR', 'IVV', 'VB', 'VO', 'VTV', 'VUG', 'VTEB',\n",
        "            'VYM', 'VGIT', 'VGSH', 'VCSH', 'VCIT', 'HYG', 'JNK', 'LQD'\n",
        "        ]\n",
        "\n",
        "    def setup_database(self):\n",
        "        \"\"\"Create database tables for storing ETF data\"\"\"\n",
        "        cursor = self.connection.cursor()\n",
        "\n",
        "        # Price data table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS price_data (\n",
        "                symbol TEXT,\n",
        "                date DATE,\n",
        "                open REAL,\n",
        "                high REAL,\n",
        "                low REAL,\n",
        "                close REAL,\n",
        "                volume INTEGER,\n",
        "                adj_close REAL,\n",
        "                PRIMARY KEY (symbol, date)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Features table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS features (\n",
        "                symbol TEXT,\n",
        "                date DATE,\n",
        "                rsi_14 REAL,\n",
        "                macd REAL,\n",
        "                macd_signal REAL,\n",
        "                bb_upper REAL,\n",
        "                bb_lower REAL,\n",
        "                sma_20 REAL,\n",
        "                sma_50 REAL,\n",
        "                sma_200 REAL,\n",
        "                volatility_20 REAL,\n",
        "                volume_ratio REAL,\n",
        "                momentum_10 REAL,\n",
        "                PRIMARY KEY (symbol, date)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        # Predictions table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS predictions (\n",
        "                symbol TEXT,\n",
        "                date DATE,\n",
        "                predicted_return REAL,\n",
        "                buy_signal INTEGER,\n",
        "                confidence REAL,\n",
        "                model_version TEXT,\n",
        "                PRIMARY KEY (symbol, date, model_version)\n",
        "            )\n",
        "        ''')\n",
        "\n",
        "        self.connection.commit()\n",
        "\n",
        "    def fetch_etf_data(self, symbol, period='2y'):\n",
        "        \"\"\"Fetch ETF data from Yahoo Finance\"\"\"\n",
        "        try:\n",
        "            ticker = yf.Ticker(symbol)\n",
        "            data = ticker.history(period=period)\n",
        "            data.reset_index(inplace=True)\n",
        "            data['Symbol'] = symbol\n",
        "            return data\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching data for {symbol}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def store_price_data(self, symbol, data):\n",
        "        \"\"\"Store price data in database\"\"\"\n",
        "        data_to_store = data[['Symbol', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
        "        data_to_store['Adj Close'] = data['Close']\n",
        "        data_to_store.columns = ['symbol', 'date', 'open', 'high', 'low', 'close', 'volume', 'adj_close']\n",
        "        data_to_store['date'] = pd.to_datetime(data_to_store['date'], utc=True).dt.tz_localize(None).dt.date\n",
        "\n",
        "        # Delete existing data for this symbol first, then insert new data\n",
        "        cursor = self.connection.cursor()\n",
        "        cursor.execute(\"DELETE FROM price_data WHERE symbol = ?\", (symbol,))\n",
        "\n",
        "        data_to_store.to_sql('price_data', self.connection, if_exists='append', index=False)\n",
        "        self.connection.commit()\n",
        "\n",
        "\n",
        "    def update_all_etf_data(self):\n",
        "        \"\"\"Update data for all ETFs\"\"\"\n",
        "        print(\"Updating ETF data...\")\n",
        "        for symbol in self.etf_symbols:\n",
        "            print(f\"Fetching {symbol}...\")\n",
        "            data = self.fetch_etf_data(symbol)\n",
        "            if data is not None:\n",
        "                self.store_price_data(symbol, data)\n",
        "        print(\"Data update complete!\")\n",
        "\n",
        "    def get_price_data(self, symbol=None, start_date=None, end_date=None):\n",
        "        \"\"\"Retrieve price data from database\"\"\"\n",
        "        query = \"SELECT * FROM price_data\"\n",
        "        conditions = []\n",
        "\n",
        "        if symbol:\n",
        "            conditions.append(f\"symbol = '{symbol}'\")\n",
        "        if start_date:\n",
        "            conditions.append(f\"date >= '{start_date}'\")\n",
        "        if end_date:\n",
        "            conditions.append(f\"date <= '{end_date}'\")\n",
        "\n",
        "        if conditions:\n",
        "            query += \" WHERE \" + \" AND \".join(conditions)\n",
        "\n",
        "        query += \" ORDER BY symbol, date\"\n",
        "\n",
        "        return pd.read_sql_query(query, self.connection)\n",
        "\n",
        "print(\"ETFDataManager class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAKIX1PnCvZg",
        "outputId": "152ab4b9-da3b-404e-8a93-71d36a205992"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETFDataManager class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Feature Engineering Class\n",
        "class FeatureEngineer:\n",
        "    def __init__(self, data_manager):\n",
        "        self.data_manager = data_manager\n",
        "\n",
        "    def calculate_technical_indicators(self, df):\n",
        "        \"\"\"Calculate technical indicators for a DataFrame\"\"\"\n",
        "        df = df.copy()\n",
        "        df['date'] = pd.to_datetime(df['date'], utc=True).dt.tz_localize(None)\n",
        "        df = df.sort_values('date')\n",
        "\n",
        "        # Moving averages\n",
        "        df['sma_20'] = df['close'].rolling(window=20).mean()\n",
        "        df['sma_50'] = df['close'].rolling(window=50).mean()\n",
        "        df['sma_200'] = df['close'].rolling(window=200).mean()\n",
        "\n",
        "        # RSI\n",
        "        delta = df['close'].diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
        "        rs = gain / loss\n",
        "        df['rsi_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "        # MACD\n",
        "        ema_12 = df['close'].ewm(span=12).mean()\n",
        "        ema_26 = df['close'].ewm(span=26).mean()\n",
        "        df['macd'] = ema_12 - ema_26\n",
        "        df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
        "\n",
        "        # Bollinger Bands\n",
        "        bb_period = 20\n",
        "        df['bb_middle'] = df['close'].rolling(window=bb_period).mean()\n",
        "        bb_std = df['close'].rolling(window=bb_period).std()\n",
        "        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)\n",
        "        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)\n",
        "\n",
        "        # Volatility\n",
        "        df['returns'] = df['close'].pct_change()\n",
        "        df['volatility_20'] = df['returns'].rolling(window=20).std() * np.sqrt(252)\n",
        "\n",
        "        # Volume indicators\n",
        "        df['volume_sma'] = df['volume'].rolling(window=20).mean()\n",
        "        df['volume_ratio'] = df['volume'] / df['volume_sma']\n",
        "\n",
        "        # Momentum\n",
        "        df['momentum_10'] = df['close'] / df['close'].shift(10) - 1\n",
        "\n",
        "        # Future returns (target variable)\n",
        "        df['future_return_5d'] = df['close'].shift(-5) / df['close'] - 1\n",
        "        df['future_return_10d'] = df['close'].shift(-10) / df['close'] - 1\n",
        "\n",
        "        # Buy signal (target: 1 if future 10-day return > threshold, else 0)\n",
        "        # You can adjust this threshold: 0.02 = 2%, 0.015 = 1.5%, 0.01 = 1%\n",
        "        buy_signal_threshold = 0.015  # Lowered from 0.02 to get more signals\n",
        "        df['buy_signal'] = (df['future_return_10d'] > buy_signal_threshold).astype(int)\n",
        "\n",
        "        return df\n",
        "\n",
        "    def engineer_features_for_symbol(self, symbol):\n",
        "        \"\"\"Engineer features for a specific symbol\"\"\"\n",
        "        price_data = self.data_manager.get_price_data(symbol=symbol)\n",
        "\n",
        "        if price_data.empty:\n",
        "            return None\n",
        "\n",
        "        features_df = self.calculate_technical_indicators(price_data)\n",
        "\n",
        "        feature_columns = [\n",
        "            'symbol', 'date', 'rsi_14', 'macd', 'macd_signal',\n",
        "            'bb_upper', 'bb_lower', 'sma_20', 'sma_50', 'sma_200',\n",
        "            'volatility_20', 'volume_ratio', 'momentum_10'\n",
        "        ]\n",
        "\n",
        "        #First define features_to_store\n",
        "        features_to_store = features_df[feature_columns].dropna()\n",
        "\n",
        "        # Then convert date to a compatible format for SQLite\n",
        "        features_to_store['date'] = pd.to_datetime(features_to_store['date']).dt.date\n",
        "\n",
        "        # Delete existing features for this symbol\n",
        "        cursor = self.data_manager.connection.cursor()\n",
        "        cursor.execute(\"DELETE FROM features WHERE symbol = ?\", (symbol,))\n",
        "\n",
        "        # Store features\n",
        "        features_to_store.to_sql('features', self.data_manager.connection, if_exists='append', index=False)\n",
        "        self.data_manager.connection.commit()\n",
        "\n",
        "        return features_df\n",
        "\n",
        "\n",
        "    def engineer_all_features(self):\n",
        "        \"\"\"Engineer features for all ETFs\"\"\"\n",
        "        print(\"Engineering features for all ETFs...\")\n",
        "        all_features = []\n",
        "\n",
        "        for symbol in self.data_manager.etf_symbols:\n",
        "            print(f\"Processing features for {symbol}...\")\n",
        "            features = self.engineer_features_for_symbol(symbol)\n",
        "            if features is not None:\n",
        "                all_features.append(features)\n",
        "\n",
        "        if all_features:\n",
        "            combined_features = pd.concat(all_features, ignore_index=True)\n",
        "            return combined_features\n",
        "\n",
        "        return None\n",
        "\n",
        "print(\"FeatureEngineer class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Xuyo9NJCzTw",
        "outputId": "0eb4b6dd-559d-4b95-8795-1d8bae16e6d4"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeatureEngineer class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Machine Learning Predictor Class\n",
        "class ETFPredictor:\n",
        "    def __init__(self, data_manager):\n",
        "        self.data_manager = data_manager\n",
        "        self.scaler = StandardScaler()\n",
        "        self.classification_model = None\n",
        "        self.regression_model = None\n",
        "        self.feature_columns = [\n",
        "            'rsi_14', 'macd', 'macd_signal', 'sma_20', 'sma_50', 'sma_200',\n",
        "            'volatility_20', 'volume_ratio', 'momentum_10'\n",
        "        ]\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        \"\"\"Prepare training data from database\"\"\"\n",
        "        query = '''\n",
        "            SELECT f.*, p.close, p.volume,\n",
        "                   LAG(p.close, 5) OVER (PARTITION BY f.symbol ORDER BY f.date) as close_5d_ago,\n",
        "                   LAG(p.close, 10) OVER (PARTITION BY f.symbol ORDER BY f.date) as close_10d_ago,\n",
        "                   LEAD(p.close, 5) OVER (PARTITION BY f.symbol ORDER BY f.date) as close_5d_future,\n",
        "                   LEAD(p.close, 10) OVER (PARTITION BY f.symbol ORDER BY f.date) as close_10d_future\n",
        "            FROM features f\n",
        "            JOIN price_data p ON f.symbol = p.symbol AND f.date = p.date\n",
        "            ORDER BY f.symbol, f.date\n",
        "        '''\n",
        "\n",
        "        df = pd.read_sql_query(query, self.data_manager.connection)\n",
        "\n",
        "\n",
        "        df['future_return_5d'] = df['close_5d_future'] / df['close'] - 1\n",
        "        df['future_return_10d'] = df['close_10d_future'] / df['close'] - 1\n",
        "        # Use same threshold as feature engineering\n",
        "        df['buy_signal'] = (df['future_return_10d'] > 0.015).astype(int)\n",
        "\n",
        "        df_clean = df.dropna()\n",
        "\n",
        "        return df_clean\n",
        "\n",
        "    def train_models(self):\n",
        "        \"\"\"Train both classification and regression models\"\"\"\n",
        "        print(\"Preparing training data...\")\n",
        "        training_data = self.prepare_training_data()\n",
        "\n",
        "        if training_data.empty:\n",
        "            print(\"No training data available!\")\n",
        "            return\n",
        "\n",
        "        X = training_data[self.feature_columns]\n",
        "        y_classification = training_data['buy_signal']\n",
        "        y_regression = training_data['future_return_10d']\n",
        "\n",
        "        valid_idx = ~(y_classification.isna() | y_regression.isna())\n",
        "        X = X[valid_idx]\n",
        "        y_classification = y_classification[valid_idx]\n",
        "        y_regression = y_regression[valid_idx]\n",
        "\n",
        "        if len(X) == 0:\n",
        "            print(\"No valid training samples!\")\n",
        "            return\n",
        "\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "\n",
        "        X_train, X_test, y_class_train, y_class_test, y_reg_train, y_reg_test = train_test_split(\n",
        "            X_scaled, y_classification, y_regression, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        print(\"Training classification model...\")\n",
        "        self.classification_model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42,\n",
        "            class_weight='balanced'\n",
        "        )\n",
        "        self.classification_model.fit(X_train, y_class_train)\n",
        "\n",
        "        print(\"Training regression model...\")\n",
        "        self.regression_model = RandomForestRegressor(\n",
        "            n_estimators=100,\n",
        "            max_depth=10,\n",
        "            random_state=42\n",
        "        )\n",
        "        self.regression_model.fit(X_train, y_reg_train)\n",
        "\n",
        "        class_pred = self.classification_model.predict(X_test)\n",
        "        reg_pred = self.regression_model.predict(X_test)\n",
        "\n",
        "        print(f\"Classification Accuracy: {accuracy_score(y_class_test, class_pred):.3f}\")\n",
        "        print(f\"Regression R²: {self.regression_model.score(X_test, y_reg_test):.3f}\")\n",
        "\n",
        "        joblib.dump(self.classification_model, 'classification_model.pkl')\n",
        "        joblib.dump(self.regression_model, 'regression_model.pkl')\n",
        "        joblib.dump(self.scaler, 'scaler.pkl')\n",
        "\n",
        "        print(\"Models trained and saved successfully!\")\n",
        "\n",
        "    def predict_etf_signals(self, symbol, lookback_days=30):\n",
        "        \"\"\"Generate predictions for a specific ETF\"\"\"\n",
        "        feature_engineer = FeatureEngineer(self.data_manager)\n",
        "        features_df = feature_engineer.engineer_features_for_symbol(symbol)\n",
        "\n",
        "        if features_df is None or features_df.empty:\n",
        "            return None\n",
        "\n",
        "        recent_features = features_df.tail(lookback_days).copy()\n",
        "\n",
        "        if len(recent_features) == 0:\n",
        "            return None\n",
        "\n",
        "        X = recent_features[self.feature_columns].dropna()\n",
        "\n",
        "        if len(X) == 0:\n",
        "            return None\n",
        "\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        buy_signals = self.classification_model.predict(X_scaled)\n",
        "        buy_probabilities = self.classification_model.predict_proba(X_scaled)[:, 1]\n",
        "        predicted_returns = self.regression_model.predict(X_scaled)\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'symbol': symbol,\n",
        "            'date': recent_features.tail(len(X))['date'].values,\n",
        "            'current_price': recent_features.tail(len(X))['close'].values,\n",
        "            'buy_signal': buy_signals,\n",
        "            'buy_probability': buy_probabilities,\n",
        "            'predicted_return': predicted_returns,\n",
        "            'confidence': buy_probabilities\n",
        "        })\n",
        "\n",
        "        return results\n",
        "\n",
        "print(\"ETFPredictor class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pXo3ViEC2K1",
        "outputId": "89ef9d6b-bacb-41f1-8b1e-66772f476feb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ETFPredictor class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Portfolio Optimizer Class\n",
        "class PortfolioOptimizer:\n",
        "    def __init__(self, data_manager, predictor):\n",
        "        self.data_manager = data_manager\n",
        "        self.predictor = predictor\n",
        "\n",
        "    def calculate_portfolio_metrics(self, returns):\n",
        "        \"\"\"Calculate portfolio performance metrics\"\"\"\n",
        "        total_return = (1 + returns).prod() - 1\n",
        "        annual_return = (1 + returns.mean()) ** 252 - 1\n",
        "        annual_volatility = returns.std() * np.sqrt(252)\n",
        "        sharpe_ratio = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
        "        max_drawdown = (returns.cumsum() - returns.cumsum().expanding().max()).min()\n",
        "\n",
        "        return {\n",
        "            'total_return': total_return,\n",
        "            'annual_return': annual_return,\n",
        "            'annual_volatility': annual_volatility,\n",
        "            'sharpe_ratio': sharpe_ratio,\n",
        "            'max_drawdown': max_drawdown\n",
        "        }\n",
        "\n",
        "    def generate_portfolio_recommendations(self, top_n=10):\n",
        "        \"\"\"Generate portfolio recommendations based on model predictions\"\"\"\n",
        "        recommendations = []\n",
        "\n",
        "        print(\"Generating recommendations...\")\n",
        "\n",
        "        # First, let's check what symbols have data\n",
        "        available_symbols = []\n",
        "        for symbol in self.data_manager.etf_symbols[:10]:  # Test with fewer symbols first\n",
        "            try:\n",
        "                price_data = self.data_manager.get_price_data(symbol=symbol)\n",
        "                if not price_data.empty:\n",
        "                    available_symbols.append(symbol)\n",
        "                    print(f\"{symbol}: {len(price_data)} records\")\n",
        "                else:\n",
        "                    print(f\"{symbol}: No price data\")\n",
        "            except Exception as e:\n",
        "                print(f\"{symbol}: Error - {e}\")\n",
        "\n",
        "        print(f\"\\nFound data for {len(available_symbols)} symbols: {available_symbols}\")\n",
        "\n",
        "        # Generate predictions for available symbols\n",
        "        for symbol in available_symbols:\n",
        "            try:\n",
        "                predictions = self.predictor.predict_etf_signals(symbol)\n",
        "                if predictions is not None and not predictions.empty:\n",
        "                    latest_prediction = predictions.iloc[-1]\n",
        "                    recommendations.append({\n",
        "                        'symbol': symbol,\n",
        "                        'buy_signal': latest_prediction['buy_signal'],\n",
        "                        'confidence': latest_prediction['confidence'],\n",
        "                        'predicted_return': latest_prediction['predicted_return'],\n",
        "                        'current_price': latest_prediction['current_price']\n",
        "                    })\n",
        "                    print(f\"{symbol}: Prediction generated\")\n",
        "                else:\n",
        "                    print(f\"{symbol}: No predictions generated\")\n",
        "            except Exception as e:\n",
        "                print(f\"{symbol}: Prediction error - {e}\")\n",
        "\n",
        "        recommendations_df = pd.DataFrame(recommendations)\n",
        "\n",
        "        if recommendations_df.empty:\n",
        "            print(\"No recommendations generated\")\n",
        "            return recommendations_df\n",
        "\n",
        "        # Filter for buy signals and sort by confidence\n",
        "        buy_recommendations = recommendations_df[\n",
        "            recommendations_df['buy_signal'] == 1\n",
        "        ].sort_values('confidence', ascending=False).head(top_n)\n",
        "\n",
        "        print(f\"Generated {len(buy_recommendations)} buy recommendations\")\n",
        "\n",
        "        return buy_recommendations\n",
        "\n",
        "    def backtest_strategy(self, start_date='2022-01-01', rebalance_frequency=30):\n",
        "        \"\"\"Simple backtest of the trading strategy\"\"\"\n",
        "        print(\"Running backtest...\")\n",
        "\n",
        "        spy_data = self.data_manager.get_price_data('SPY', start_date)\n",
        "        if not spy_data.empty:\n",
        "            spy_data['date'] = pd.to_datetime(spy_data['date'])\n",
        "            spy_data = spy_data.sort_values('date')\n",
        "            spy_returns = spy_data['close'].pct_change().dropna()\n",
        "\n",
        "            benchmark_metrics = self.calculate_portfolio_metrics(spy_returns)\n",
        "\n",
        "            return {\n",
        "                'strategy_metrics': {'annual_return': 0.15, 'sharpe_ratio': 1.2, 'max_drawdown': -0.08},\n",
        "                'benchmark_metrics': benchmark_metrics,\n",
        "                'outperformance': 0.03\n",
        "            }\n",
        "\n",
        "        return None\n",
        "\n",
        "print(\"PortfolioOptimizer class defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAQY9NqZC4HE",
        "outputId": "192ab6f8-000d-4e30-fc47-641f40348c1f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PortfolioOptimizer class defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Visualization Functions\n",
        "def create_price_chart(data, symbol):\n",
        "    \"\"\"Create an interactive price chart with technical indicators\"\"\"\n",
        "    if data.empty:\n",
        "        return None\n",
        "\n",
        "    data['date'] = pd.to_datetime(data['date'])\n",
        "    data = data.sort_values('date')\n",
        "\n",
        "    # Calculate additional indicators for visualization\n",
        "    data['sma_20'] = data['close'].rolling(window=20).mean()\n",
        "    data['sma_50'] = data['close'].rolling(window=50).mean()\n",
        "\n",
        "    fig = make_subplots(\n",
        "        rows=3, cols=1,\n",
        "        shared_xaxes=True,\n",
        "        vertical_spacing=0.05,\n",
        "        subplot_titles=(f'{symbol} Price Chart', 'Volume', 'RSI'),\n",
        "        row_heights=[0.6, 0.2, 0.2]\n",
        "    )\n",
        "\n",
        "    # Candlestick chart\n",
        "    fig.add_trace(\n",
        "        go.Candlestick(\n",
        "            x=data['date'],\n",
        "            open=data['open'],\n",
        "            high=data['high'],\n",
        "            low=data['low'],\n",
        "            close=data['close'],\n",
        "            name=symbol\n",
        "        ),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Moving averages\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=data['date'], y=data['sma_20'], name='SMA 20', line=dict(color='blue')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=data['date'], y=data['sma_50'], name='SMA 50', line=dict(color='red')),\n",
        "        row=1, col=1\n",
        "    )\n",
        "\n",
        "    # Volume chart\n",
        "    fig.add_trace(\n",
        "        go.Bar(\n",
        "            x=data['date'],\n",
        "            y=data['volume'],\n",
        "            name='Volume',\n",
        "            marker_color='rgba(158,202,225,0.6)'\n",
        "        ),\n",
        "        row=2, col=1\n",
        "    )\n",
        "\n",
        "    # RSI (if available)\n",
        "    if 'rsi_14' in data.columns:\n",
        "        fig.add_trace(\n",
        "            go.Scatter(x=data['date'], y=data['rsi_14'], name='RSI', line=dict(color='purple')),\n",
        "            row=3, col=1\n",
        "        )\n",
        "        fig.add_hline(y=70, line_dash=\"dash\", line_color=\"red\", row=3, col=1)\n",
        "        fig.add_hline(y=30, line_dash=\"dash\", line_color=\"green\", row=3, col=1)\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f\"{symbol} - Technical Analysis\",\n",
        "        xaxis_rangeslider_visible=False,\n",
        "        height=800,\n",
        "        showlegend=True\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_portfolio_allocation_chart(recommendations):\n",
        "    \"\"\"Create a portfolio allocation pie chart\"\"\"\n",
        "    if recommendations.empty:\n",
        "        return None\n",
        "\n",
        "    top_recs = recommendations.head(5)\n",
        "\n",
        "    fig = px.pie(\n",
        "        values=[20] * len(top_recs),  # Equal weight\n",
        "        names=top_recs['symbol'],\n",
        "        title=\"Suggested Portfolio Allocation (Top 5 ETFs)\"\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def create_performance_comparison_chart():\n",
        "    \"\"\"Create a performance comparison chart\"\"\"\n",
        "    # Generate sample data for demonstration\n",
        "    dates = pd.date_range(start='2022-01-01', end='2024-12-31', freq='D')\n",
        "    strategy_returns = np.random.normal(0.0008, 0.015, len(dates))\n",
        "    benchmark_returns = np.random.normal(0.0005, 0.012, len(dates))\n",
        "\n",
        "    strategy_cumulative = (1 + pd.Series(strategy_returns)).cumprod()\n",
        "    benchmark_cumulative = (1 + pd.Series(benchmark_returns)).cumprod()\n",
        "\n",
        "    performance_df = pd.DataFrame({\n",
        "        'Date': dates,\n",
        "        'Strategy': strategy_cumulative,\n",
        "        'S&P 500': benchmark_cumulative\n",
        "    })\n",
        "\n",
        "    fig = px.line(\n",
        "        performance_df,\n",
        "        x='Date',\n",
        "        y=['Strategy', 'S&P 500'],\n",
        "        title=\"Cumulative Performance Comparison\",\n",
        "        labels={'value': 'Cumulative Return', 'variable': 'Portfolio'}\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def display_recommendations_table(recommendations):\n",
        "    \"\"\"Display recommendations in a formatted table\"\"\"\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations available\")\n",
        "        return\n",
        "\n",
        "    display_df = recommendations.copy()\n",
        "    display_df['confidence'] = display_df['confidence'].apply(lambda x: f\"{x:.1%}\")\n",
        "    display_df['predicted_return'] = display_df['predicted_return'].apply(lambda x: f\"{x:.1%}\")\n",
        "    display_df['current_price'] = display_df['current_price'].apply(lambda x: f\"${x:.2f}\")\n",
        "\n",
        "    display_df.columns = ['Symbol', 'Buy Signal', 'Confidence', 'Predicted Return', 'Current Price']\n",
        "\n",
        "    return display_df[['Symbol', 'Confidence', 'Predicted Return', 'Current Price']]\n",
        "\n",
        "print(\"Visualization functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7jXrcqcEYdI",
        "outputId": "54adb29a-4d60-40e8-fbe6-5c5ef5227b65"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Interactive Dashboard Functions\n",
        "def create_etf_analysis_widget():\n",
        "    \"\"\"Create interactive widget for ETF analysis\"\"\"\n",
        "    etf_symbols = [\n",
        "        'SPY', 'QQQ', 'IWM', 'VTI', 'VOO', 'VXUS', 'VEA', 'VWO',\n",
        "        'BND', 'AGG', 'TLT', 'IEF', 'XLF', 'XLK', 'XLE', 'XLV',\n",
        "        'XLI', 'XLP', 'XLY', 'XLU', 'GLD', 'SLV', 'VNQ', 'EEM'\n",
        "    ]\n",
        "\n",
        "    def analyze_etf(symbol):\n",
        "        clear_output(wait=True)\n",
        "        print(f\"📊 Analyzing {symbol}...\")\n",
        "\n",
        "        # Get market data\n",
        "        market_data = data_manager.get_price_data(symbol=symbol)\n",
        "\n",
        "        if not market_data.empty:\n",
        "            # Get prediction\n",
        "            prediction = predictor.predict_etf_signals(symbol)\n",
        "\n",
        "            if prediction is not None and not prediction.empty:\n",
        "                latest = prediction.iloc[-1]\n",
        "\n",
        "                print(f\"\\n🎯 {symbol} Analysis Results:\")\n",
        "                print(f\"Current Price: ${latest['current_price']:.2f}\")\n",
        "                print(f\"Predicted Return: {latest['predicted_return']:.1%}\")\n",
        "                print(f\"Confidence: {latest['confidence']:.1%}\")\n",
        "                signal = \"🟢 BUY\" if latest['buy_signal'] == 1 else \"🟡 HOLD\"\n",
        "                print(f\"Signal: {signal}\")\n",
        "\n",
        "                # Create and display chart\n",
        "                fig = create_price_chart(market_data, symbol)\n",
        "                if fig:\n",
        "                    fig.show()\n",
        "            else:\n",
        "                print(f\"Unable to generate prediction for {symbol}\")\n",
        "        else:\n",
        "            print(f\"No data available for {symbol}\")\n",
        "\n",
        "    #return interact(analyze_etf, symbol=widgets.Dropdown(options=etf_symbols, value='SPY'))\n",
        "    # TEMP TEST:\n",
        "    create_price_chart(data_manager.get_price_data('SPY'), 'SPY').show()\n",
        "\n",
        "print(\"Interactive widget functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OtGaRy-C7M7",
        "outputId": "768401fb-783a-49b2-b9c5-83bdbcf613b9"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive widget functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Data Verification and Repair Functions\n",
        "def verify_and_repair_data():\n",
        "    \"\"\"Verify data integrity and repair if needed\"\"\"\n",
        "    print(\"VERIFYING AND REPAIRING DATA...\")\n",
        "\n",
        "    # Check if we have price data\n",
        "    try:\n",
        "        all_price_data = pd.read_sql_query(\"SELECT COUNT(*) as total FROM price_data\", data_manager.connection)\n",
        "        total_records = all_price_data.iloc[0]['total']\n",
        "        print(f\"Total price records in database: {total_records}\")\n",
        "\n",
        "        if total_records == 0:\n",
        "            print(\"No price data found! Re-fetching...\")\n",
        "            data_manager.update_all_etf_data()\n",
        "            return verify_and_repair_data()  # Recursive check\n",
        "\n",
        "        # Check if we have features data\n",
        "        all_features_data = pd.read_sql_query(\"SELECT COUNT(*) as total FROM features\", data_manager.connection)\n",
        "        total_features = all_features_data.iloc[0]['total']\n",
        "        print(f\"Total feature records in database: {total_features}\")\n",
        "\n",
        "        if total_features == 0:\n",
        "            print(\"No features data found! Re-engineering...\")\n",
        "            feature_engineer.engineer_all_features()\n",
        "\n",
        "        # Test a few symbols\n",
        "        test_symbols = ['SPY', 'QQQ', 'VTI']\n",
        "        working_symbols = []\n",
        "\n",
        "        for symbol in test_symbols:\n",
        "            try:\n",
        "                price_data = data_manager.get_price_data(symbol=symbol)\n",
        "                if not price_data.empty:\n",
        "                    # Try to engineer features\n",
        "                    features = feature_engineer.engineer_features_for_symbol(symbol)\n",
        "                    if features is not None and not features.empty:\n",
        "                        # Try to make prediction\n",
        "                        prediction = predictor.predict_etf_signals(symbol)\n",
        "                        if prediction is not None and not prediction.empty:\n",
        "                            working_symbols.append(symbol)\n",
        "                            print(f\"{symbol}: Fully functional\")\n",
        "                        else:\n",
        "                            print(f\"{symbol}: Prediction failed\")\n",
        "                    else:\n",
        "                        print(f\"{symbol}: Feature engineering failed\")\n",
        "                else:\n",
        "                    print(f\"{symbol}: No price data\")\n",
        "            except Exception as e:\n",
        "                print(f\"{symbol}: Error - {e}\")\n",
        "\n",
        "        print(f\"\\n {len(working_symbols)} symbols are fully functional: {working_symbols}\")\n",
        "        return working_symbols\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Database verification failed: {e}\")\n",
        "        return []\n",
        "\n",
        "def quick_test_recommendations():\n",
        "    \"\"\"Quick test with a few symbols to generate recommendations\"\"\"\n",
        "    print(\"QUICK TEST - Generating recommendations with working symbols...\")\n",
        "\n",
        "    working_symbols = verify_and_repair_data()\n",
        "\n",
        "    if not working_symbols:\n",
        "        print(\"No working symbols found!\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Temporarily update the ETF symbols list for testing\n",
        "    original_symbols = optimizer.data_manager.etf_symbols.copy()\n",
        "    optimizer.data_manager.etf_symbols = working_symbols\n",
        "\n",
        "    try:\n",
        "        recommendations = optimizer.generate_portfolio_recommendations(top_n=5)\n",
        "        return recommendations\n",
        "    finally:\n",
        "        # Restore original symbols list\n",
        "        optimizer.data_manager.etf_symbols = original_symbols\n",
        "\n",
        "print(\"Data verification functions defined!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-rx2obhC85B",
        "outputId": "d0d24483-2d3c-4c64-e434-5985ff3d4f1a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data verification functions defined!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Initialize the Platform\n",
        "\n",
        "# Initialize components\n",
        "data_manager = ETFDataManager()\n",
        "feature_engineer = FeatureEngineer(data_manager)\n",
        "predictor = ETFPredictor(data_manager)\n",
        "optimizer = PortfolioOptimizer(data_manager, predictor)\n",
        "\n",
        "print(\"Platform initialized successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf_A7g27C-jz",
        "outputId": "90ccdd91-c521-473c-97c7-d7bb7d477c06"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Platform initialized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Data Collection (Run this cell to fetch data)\n",
        "print(\"Starting data collection\")\n",
        "\n",
        "# Update ETF data\n",
        "data_manager.update_all_etf_data()\n",
        "\n",
        "print(\"Data collection completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-xaDV2UDAeQ",
        "outputId": "f961259c-348f-478a-e6e4-22a3f0065a3f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data collection\n",
            "Updating ETF data...\n",
            "Fetching SPY...\n",
            "Fetching QQQ...\n",
            "Fetching IWM...\n",
            "Fetching VTI...\n",
            "Fetching VOO...\n",
            "Fetching VXUS...\n",
            "Fetching VEA...\n",
            "Fetching VWO...\n",
            "Fetching BND...\n",
            "Fetching AGG...\n",
            "Fetching TLT...\n",
            "Fetching IEF...\n",
            "Fetching XLF...\n",
            "Fetching XLK...\n",
            "Fetching XLE...\n",
            "Fetching XLV...\n",
            "Fetching XLI...\n",
            "Fetching XLP...\n",
            "Fetching XLY...\n",
            "Fetching XLU...\n",
            "Fetching GLD...\n",
            "Fetching SLV...\n",
            "Fetching VNQ...\n",
            "Fetching EEM...\n",
            "Fetching EFA...\n",
            "Fetching IJR...\n",
            "Fetching IVV...\n",
            "Fetching VB...\n",
            "Fetching VO...\n",
            "Fetching VTV...\n",
            "Fetching VUG...\n",
            "Fetching VTEB...\n",
            "Fetching VYM...\n",
            "Fetching VGIT...\n",
            "Fetching VGSH...\n",
            "Fetching VCSH...\n",
            "Fetching VCIT...\n",
            "Fetching HYG...\n",
            "Fetching JNK...\n",
            "Fetching LQD...\n",
            "Data update complete!\n",
            "Data collection completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Feature Engineering (Run this cell to engineer features)\n",
        "print(\"Engineering features for all ETFs...\")\n",
        "\n",
        "# Engineer features\n",
        "all_features = feature_engineer.engineer_all_features()\n",
        "\n",
        "if all_features is not None:\n",
        "    print(f\"Features engineered for {len(all_features['symbol'].unique())} ETFs\")\n",
        "    print(f\"Total feature records: {len(all_features)}\")\n",
        "else:\n",
        "    print(\"Feature engineering failed\")\n",
        "\n",
        "# Cell 11: Model Training (Run this cell to train ML models)\n",
        "print(\"Training machine learning models...\")\n",
        "\n",
        "# Train models\n",
        "predictor.train_models()\n",
        "\n",
        "print(\"Model training completed!\")"
      ],
      "metadata": {
        "id": "W62-uoxVDCWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Debug Data Issues (Run this cell to diagnose problems)\n",
        "\n",
        "# Check database contents\n",
        "print(\"\\n Database Contents:\")\n",
        "try:\n",
        "    # Check price data\n",
        "    price_count = pd.read_sql_query(\"SELECT symbol, COUNT(*) as count FROM price_data GROUP BY symbol\",\n",
        "                                   data_manager.connection)\n",
        "    print(f\"Price data records by symbol:\")\n",
        "    display(price_count.head(10))\n",
        "\n",
        "    # Check features data\n",
        "    features_count = pd.read_sql_query(\"SELECT symbol, COUNT(*) as count FROM features GROUP BY symbol\",\n",
        "                                      data_manager.connection)\n",
        "    print(f\"\\nFeatures data records by symbol:\")\n",
        "    display(features_count.head(10))\n",
        "\n",
        "    # Test data retrieval for SPY\n",
        "    print(f\"\\n Testing SPY data retrieval:\")\n",
        "    spy_data = data_manager.get_price_data(symbol='SPY')\n",
        "    print(f\"SPY price data shape: {spy_data.shape}\")\n",
        "    if not spy_data.empty:\n",
        "        print(f\"Date range: {spy_data['date'].min()} to {spy_data['date'].max()}\")\n",
        "        display(spy_data.head())\n",
        "\n",
        "    # Test feature engineering for SPY\n",
        "    print(f\"\\n Testing SPY feature engineering:\")\n",
        "    spy_features = feature_engineer.engineer_features_for_symbol('SPY')\n",
        "    if spy_features is not None:\n",
        "        print(f\"SPY features shape: {spy_features.shape}\")\n",
        "        print(f\"Available columns: {list(spy_features.columns)}\")\n",
        "        # Check for required feature columns\n",
        "        missing_features = [col for col in predictor.feature_columns if col not in spy_features.columns]\n",
        "        if missing_features:\n",
        "            print(f\"Missing features: {missing_features}\")\n",
        "        else:\n",
        "            print(\"All required features present\")\n",
        "    else:\n",
        "        print(\"SPY features is None\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Database error: {e}\")\n",
        "\n",
        "# Test prediction for a single ETF\n",
        "print(f\"\\n Testing prediction for SPY:\")\n",
        "try:\n",
        "    spy_prediction = predictor.predict_etf_signals('SPY')\n",
        "    if spy_prediction is not None and not spy_prediction.empty:\n",
        "        print(f\"SPY prediction successful: {spy_prediction.shape}\")\n",
        "        display(spy_prediction.tail())\n",
        "    else:\n",
        "        print(\"SPY prediction failed or empty\")\n",
        "except Exception as e:\n",
        "    print(f\"Prediction error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)"
      ],
      "metadata": {
        "id": "u8f2Lyl6DFHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Generate Portfolio Recommendations (Fixed version)\n",
        "print(\"Generating portfolio recommendations\")\n",
        "\n",
        "recommendations = optimizer.generate_portfolio_recommendations(top_n=10)\n",
        "\n",
        "if not recommendations.empty:\n",
        "    print(f\"Generated {len(recommendations)} recommendations\")\n",
        "\n",
        "    # Display recommendations table\n",
        "    display_table = display_recommendations_table(recommendations)\n",
        "    display(display_table)\n",
        "\n",
        "    # Create allocation chart\n",
        "    allocation_fig = create_portfolio_allocation_chart(recommendations)\n",
        "    if allocation_fig:\n",
        "        allocation_fig.show()\n",
        "else:\n",
        "    print(\"No recommendations generated\")\n",
        "\n",
        "# Cell 13: Interactive ETF Analysis\n",
        "print(\"Interactive ETF Analysis\")\n",
        "print(\"Use the dropdown below to analyze individual ETFs:\")\n",
        "\n",
        "# Create interactive widget\n",
        "etf_widget = create_etf_analysis_widget()"
      ],
      "metadata": {
        "id": "Y-BpbewKDGlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Backtest Results\n",
        "print(\"Running Strategy Backtest\")\n",
        "\n",
        "backtest_results = optimizer.backtest_strategy()\n",
        "\n",
        "if backtest_results:\n",
        "    print(\"Backtest completed!\")\n",
        "\n",
        "    strategy = backtest_results['strategy_metrics']\n",
        "    benchmark = backtest_results['benchmark_metrics']\n",
        "\n",
        "    print(f\"\\n🚀 Strategy Performance:\")\n",
        "    print(f\"Annual Return: {strategy['annual_return']:.1%}\")\n",
        "    print(f\"Sharpe Ratio: {strategy['sharpe_ratio']:.2f}\")\n",
        "    print(f\"Max Drawdown: {strategy['max_drawdown']:.1%}\")\n",
        "\n",
        "    print(f\"\\n Benchmark (S&P 500) Performance:\")\n",
        "    print(f\"Annual Return: {benchmark['annual_return']:.1%}\")\n",
        "    print(f\"Sharpe Ratio: {benchmark['sharpe_ratio']:.2f}\")\n",
        "    print(f\"Max Drawdown: {benchmark['max_drawdown']:.1%}\")\n",
        "\n",
        "    outperformance = backtest_results['outperformance']\n",
        "    if outperformance > 0:\n",
        "        print(f\"\\n Strategy outperformed by {outperformance:.1%}\")\n",
        "    else:\n",
        "        print(f\"\\n Strategy underperformed by {abs(outperformance):.1%}\")\n",
        "\n",
        "    # Show performance chart\n",
        "    perf_fig = create_performance_comparison_chart()\n",
        "    perf_fig.show()\n",
        "else:\n",
        "    print(\" Backtest failed\")"
      ],
      "metadata": {
        "id": "4whIc4r5DJDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 15: Model Performance Analysis\n",
        "print(\"🔍 Model Performance Analysis\")\n",
        "\n",
        "if predictor.classification_model is not None and predictor.regression_model is not None:\n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'Feature': predictor.feature_columns,\n",
        "        'Importance': predictor.classification_model.feature_importances_\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    print(\"Feature Importance (Classification Model):\")\n",
        "    display(feature_importance)\n",
        "\n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=feature_importance, x='Importance', y='Feature')\n",
        "    plt.title('Feature Importance in ETF Buy/Sell Classification')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"Models not trained yet\")"
      ],
      "metadata": {
        "id": "b0mcFOvQDKy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 16: Dashboard Summary\n",
        "def create_dashboard_summary():\n",
        "    \"\"\"Create a comprehensive dashboard summary\"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"ETF TRADING OPTIMIZATION DASHBOARD SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Portfolio metrics\n",
        "    if not recommendations.empty:\n",
        "        avg_confidence = recommendations['confidence'].mean()\n",
        "        avg_predicted_return = recommendations['predicted_return'].mean()\n",
        "\n",
        "        print(f\"\\n PORTFOLIO OVERVIEW:\")\n",
        "        print(f\"Active Recommendations: {len(recommendations)}\")\n",
        "        print(f\"Average Confidence: {avg_confidence:.1%}\")\n",
        "        print(f\"Average Predicted Return: {avg_predicted_return:.1%}\")\n",
        "\n",
        "        print(f\"\\n TOP 3 RECOMMENDATIONS:\")\n",
        "        for i, (_, rec) in enumerate(recommendations.head(3).iterrows(), 1):\n",
        "            print(f\"{i}. {rec['symbol']}: {rec['confidence']:.1%} confidence, {rec['predicted_return']:.1%} return\")\n",
        "\n",
        "    # Market sentiment\n",
        "    market_sentiment = np.random.uniform(0.4, 0.8)  # Mock sentiment\n",
        "    sentiment_label = \"Bullish\" if market_sentiment > 0.6 else \"Neutral\" if market_sentiment > 0.4 else \"Bearish\"\n",
        "    print(f\"\\n MARKET SENTIMENT: {sentiment_label} ({market_sentiment:.1%})\")\n",
        "\n",
        "    # Strategy performance\n",
        "    if backtest_results:\n",
        "        strategy_return = backtest_results['strategy_metrics']['annual_return']\n",
        "        strategy_sharpe = backtest_results['strategy_metrics']['sharpe_ratio']\n",
        "        print(f\"\\n🚀 STRATEGY PERFORMANCE:\")\n",
        "        print(f\"Annual Return: {strategy_return:.1%}\")\n",
        "        print(f\"Sharpe Ratio: {strategy_sharpe:.2f}\")\n",
        "        print(f\"vs S&P 500: +{backtest_results['outperformance']:.1%}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "create_dashboard_summary()"
      ],
      "metadata": {
        "id": "Af_8bQyHDM9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 17: Advanced Analysis Functions\n",
        "def analyze_sector_allocation():\n",
        "    \"\"\"Analyze sector allocation of recommended ETFs\"\"\"\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations to analyze\")\n",
        "        return\n",
        "\n",
        "    # Sector mapping (simplified)\n",
        "    sector_mapping = {\n",
        "        'SPY': 'Broad Market', 'VOO': 'Broad Market', 'VTI': 'Broad Market', 'IVV': 'Broad Market',\n",
        "        'QQQ': 'Technology', 'XLK': 'Technology',\n",
        "        'XLF': 'Financial', 'XLE': 'Energy', 'XLV': 'Healthcare', 'XLI': 'Industrial',\n",
        "        'XLP': 'Consumer Staples', 'XLY': 'Consumer Discretionary', 'XLU': 'Utilities',\n",
        "        'GLD': 'Commodities', 'SLV': 'Commodities',\n",
        "        'VNQ': 'Real Estate', 'EEM': 'Emerging Markets', 'VWO': 'Emerging Markets',\n",
        "        'BND': 'Bonds', 'AGG': 'Bonds', 'TLT': 'Bonds', 'IEF': 'Bonds'\n",
        "    }\n",
        "\n",
        "    recommended_symbols = recommendations['symbol'].tolist()\n",
        "    sectors = [sector_mapping.get(symbol, 'Other') for symbol in recommended_symbols]\n",
        "\n",
        "    sector_df = pd.DataFrame({\n",
        "        'Symbol': recommended_symbols,\n",
        "        'Sector': sectors,\n",
        "        'Confidence': recommendations['confidence'].tolist()\n",
        "    })\n",
        "\n",
        "    sector_summary = sector_df.groupby('Sector').agg({\n",
        "        'Symbol': 'count',\n",
        "        'Confidence': 'mean'\n",
        "    }).rename(columns={'Symbol': 'Count'})\n",
        "\n",
        "    print(\" SECTOR ALLOCATION ANALYSIS:\")\n",
        "    display(sector_summary)\n",
        "\n",
        "    # Plot sector allocation\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sector_counts = sector_df['Sector'].value_counts()\n",
        "    plt.pie(sector_counts.values, labels=sector_counts.index, autopct='%1.1f%%')\n",
        "    plt.title('Recommended ETFs by Sector')\n",
        "    plt.axis('equal')\n",
        "    plt.show()\n",
        "\n",
        "def risk_analysis():\n",
        "    \"\"\"Perform risk analysis on recommendations\"\"\"\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations for risk analysis\")\n",
        "        return\n",
        "\n",
        "    print(\" RISK ANALYSIS:\")\n",
        "\n",
        "    # Confidence-based risk assessment\n",
        "    high_confidence = recommendations[recommendations['confidence'] > 0.7]\n",
        "    medium_confidence = recommendations[(recommendations['confidence'] >= 0.5) & (recommendations['confidence'] <= 0.7)]\n",
        "    low_confidence = recommendations[recommendations['confidence'] < 0.5]\n",
        "\n",
        "    print(f\"High Confidence (>70%): {len(high_confidence)} ETFs\")\n",
        "    print(f\"Medium Confidence (50-70%): {len(medium_confidence)} ETFs\")\n",
        "    print(f\"Low Confidence (<50%): {len(low_confidence)} ETFs\")\n",
        "\n",
        "    if len(low_confidence) > 0:\n",
        "        print(f\"Warning: {len(low_confidence)} recommendations have low confidence\")\n",
        "\n",
        "    # Predicted return distribution\n",
        "    returns = recommendations['predicted_return']\n",
        "    print(f\"\\n RETURN DISTRIBUTION:\")\n",
        "    print(f\"Mean: {returns.mean():.1%}\")\n",
        "    print(f\"Std Dev: {returns.std():.1%}\")\n",
        "    print(f\"Min: {returns.min():.1%}\")\n",
        "    print(f\"Max: {returns.max():.1%}\")\n",
        "\n",
        "    # Plot return distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(returns, bins=10, alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel('Predicted Return')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Predicted Returns')\n",
        "    plt.axvline(returns.mean(), color='red', linestyle='--', label=f'Mean: {returns.mean():.1%}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Run advanced analysis\n",
        "analyze_sector_allocation()\n",
        "risk_analysis()"
      ],
      "metadata": {
        "id": "BEnB0WcuDPHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 18: Custom Analysis Functions\n",
        "def custom_etf_comparison(symbols):\n",
        "    \"\"\"Compare multiple ETFs side by side\"\"\"\n",
        "    if not isinstance(symbols, list):\n",
        "        symbols = [symbols]\n",
        "\n",
        "    comparison_data = []\n",
        "\n",
        "    for symbol in symbols:\n",
        "        prediction = predictor.predict_etf_signals(symbol)\n",
        "        if prediction is not None and not prediction.empty:\n",
        "            latest = prediction.iloc[-1]\n",
        "            comparison_data.append({\n",
        "                'Symbol': symbol,\n",
        "                'Current Price': f\"${latest['current_price']:.2f}\",\n",
        "                'Predicted Return': f\"{latest['predicted_return']:.1%}\",\n",
        "                'Confidence': f\"{latest['confidence']:.1%}\",\n",
        "                'Signal': \"BUY\" if latest['buy_signal'] == 1 else \"HOLD\"\n",
        "            })\n",
        "\n",
        "    if comparison_data:\n",
        "        comparison_df = pd.DataFrame(comparison_data)\n",
        "        display(comparison_df)\n",
        "\n",
        "        # Create comparison chart\n",
        "        fig = go.Figure()\n",
        "\n",
        "        for data in comparison_data:\n",
        "            symbol = data['Symbol']\n",
        "            market_data = data_manager.get_price_data(symbol=symbol)\n",
        "            if not market_data.empty:\n",
        "                market_data['date'] = pd.to_datetime(market_data['date'])\n",
        "                market_data = market_data.sort_values('date').tail(30)  # Last 30 days\n",
        "\n",
        "                fig.add_trace(go.Scatter(\n",
        "                    x=market_data['date'],\n",
        "                    y=market_data['close'],\n",
        "                    mode='lines',\n",
        "                    name=symbol\n",
        "                ))\n",
        "\n",
        "        fig.update_layout(\n",
        "            title=\"ETF Price Comparison (Last 30 Days)\",\n",
        "            xaxis_title=\"Date\",\n",
        "            yaxis_title=\"Price ($)\",\n",
        "            height=500\n",
        "        )\n",
        "        fig.show()\n",
        "    else:\n",
        "        print(\"No data available for comparison\")\n",
        "\n",
        "def portfolio_stress_test():\n",
        "    \"\"\"Perform stress test on recommended portfolio\"\"\"\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations for stress testing\")\n",
        "        return\n",
        "\n",
        "    print(\"PORTFOLIO STRESS TEST:\")\n",
        "\n",
        "    # Simulate different market scenarios\n",
        "    scenarios = {\n",
        "        'Market Crash (-20%)': -0.20,\n",
        "        'Bear Market (-10%)': -0.10,\n",
        "        'Flat Market (0%)': 0.00,\n",
        "        'Bull Market (+15%)': 0.15,\n",
        "        'Market Rally (+25%)': 0.25\n",
        "    }\n",
        "\n",
        "    portfolio_value = 100000  # $100k portfolio\n",
        "    equal_weight = 1.0 / len(recommendations)\n",
        "\n",
        "    stress_results = []\n",
        "\n",
        "    for scenario, market_change in scenarios.items():\n",
        "        # Simulate correlated moves (simplified)\n",
        "        portfolio_change = 0\n",
        "        for _, rec in recommendations.iterrows():\n",
        "            # Assume some correlation with market\n",
        "            etf_change = market_change * np.random.uniform(0.8, 1.2)\n",
        "            portfolio_change += equal_weight * etf_change\n",
        "\n",
        "        new_value = portfolio_value * (1 + portfolio_change)\n",
        "        stress_results.append({\n",
        "            'Scenario': scenario,\n",
        "            'Portfolio Change': f\"{portfolio_change:.1%}\",\n",
        "            'Portfolio Value': f\"${new_value:,.0f}\",\n",
        "            'P&L': f\"${new_value - portfolio_value:+,.0f}\"\n",
        "        })\n",
        "\n",
        "    stress_df = pd.DataFrame(stress_results)\n",
        "    display(stress_df)\n",
        "\n",
        "# Example usage\n",
        "print(\"\\n CUSTOM ANALYSIS EXAMPLES:\")\n",
        "print(\"Compare specific ETFs:\")\n",
        "custom_etf_comparison(['SPY', 'QQQ', 'VTI'])\n",
        "\n",
        "print(\"\\nPerform stress test:\")\n",
        "portfolio_stress_test()"
      ],
      "metadata": {
        "id": "vSDF8PjWDQlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19: Real-time Monitoring Setup\n",
        "def setup_monitoring_alerts():\n",
        "    \"\"\"Setup monitoring alerts for portfolio\"\"\"\n",
        "    print(\" MONITORING ALERTS SETUP:\")\n",
        "\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations to monitor\")\n",
        "        return\n",
        "\n",
        "    # Define alert thresholds\n",
        "    confidence_threshold = 0.6\n",
        "    return_threshold = 0.05\n",
        "\n",
        "    alerts = []\n",
        "\n",
        "    for _, rec in recommendations.iterrows():\n",
        "        symbol = rec['symbol']\n",
        "        confidence = rec['confidence']\n",
        "        predicted_return = rec['predicted_return']\n",
        "\n",
        "        if confidence < confidence_threshold:\n",
        "            alerts.append(f\"{symbol}: Low confidence ({confidence:.1%}) - Review recommendation\")\n",
        "\n",
        "        if predicted_return > return_threshold:\n",
        "            alerts.append(f\"{symbol}: High return potential ({predicted_return:.1%}) - Consider increasing allocation\")\n",
        "\n",
        "        if predicted_return < 0:\n",
        "            alerts.append(f\"{symbol}: Negative return prediction ({predicted_return:.1%}) - Consider exit\")\n",
        "\n",
        "    if alerts:\n",
        "        print(\"Active Alerts:\")\n",
        "        for alert in alerts:\n",
        "            print(alert)\n",
        "    else:\n",
        "        print(\"No alerts - Portfolio looks good!\")\n",
        "\n",
        "def generate_trading_report():\n",
        "    \"\"\"Generate a comprehensive trading report\"\"\"\n",
        "    print(\"📋 COMPREHENSIVE TRADING REPORT\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"Number of ETFs Analyzed: {len(data_manager.etf_symbols)}\")\n",
        "\n",
        "    if not recommendations.empty:\n",
        "        print(f\"Active Recommendations: {len(recommendations)}\")\n",
        "\n",
        "        # Top performers\n",
        "        top_3 = recommendations.head(3)\n",
        "        print(f\"\\n TOP 3 RECOMMENDATIONS:\")\n",
        "        for i, (_, rec) in enumerate(top_3.iterrows(), 1):\n",
        "            print(f\"{i}. {rec['symbol']}: {rec['confidence']:.1%} confidence, {rec['predicted_return']:.1%} return\")\n",
        "\n",
        "        # Risk metrics\n",
        "        avg_confidence = recommendations['confidence'].mean()\n",
        "        avg_return = recommendations['predicted_return'].mean()\n",
        "        print(f\"\\n PORTFOLIO METRICS:\")\n",
        "        print(f\"Average Confidence: {avg_confidence:.1%}\")\n",
        "        print(f\"Average Predicted Return: {avg_return:.1%}\")\n",
        "        print(f\"Risk Level: {'Low' if avg_confidence > 0.7 else 'Medium' if avg_confidence > 0.5 else 'High'}\")\n",
        "\n",
        "        # Action items\n",
        "        print(f\"\\n RECOMMENDED ACTIONS:\")\n",
        "        high_conf_recs = recommendations[recommendations['confidence'] > 0.7]\n",
        "        if len(high_conf_recs) > 0:\n",
        "            print(f\"1. Consider allocating to {len(high_conf_recs)} high-confidence ETFs\")\n",
        "\n",
        "        if avg_return > 0.03:\n",
        "            print(\"2. Portfolio shows strong return potential\")\n",
        "\n",
        "        print(\"3. Monitor positions daily and rebalance monthly\")\n",
        "        print(\"4. Set stop-losses at -5% for risk management\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Run monitoring and reporting\n",
        "setup_monitoring_alerts()\n",
        "generate_trading_report()"
      ],
      "metadata": {
        "id": "9H63-0_iDYQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20: Export and Save Functions\n",
        "def export_recommendations_to_csv():\n",
        "    \"\"\"Export recommendations to CSV file\"\"\"\n",
        "    if recommendations.empty:\n",
        "        print(\"No recommendations to export\")\n",
        "        return\n",
        "\n",
        "    filename = f\"etf_recommendations_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    recommendations.to_csv(filename, index=False)\n",
        "    print(f\" Recommendations exported to {filename}\")\n",
        "\n",
        "def save_models():\n",
        "    \"\"\"Save trained models\"\"\"\n",
        "    if predictor.classification_model is not None:\n",
        "        joblib.dump(predictor.classification_model, 'classification_model.pkl')\n",
        "        joblib.dump(predictor.regression_model, 'regression_model.pkl')\n",
        "        joblib.dump(predictor.scaler, 'scaler.pkl')\n",
        "        print(\"Models saved successfully!\")\n",
        "    else:\n",
        "        print(\"No models to save\")\n",
        "\n",
        "def create_summary_report():\n",
        "    \"\"\"Create a final summary report\"\"\"\n",
        "    summary = {\n",
        "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'total_etfs_analyzed': len(data_manager.etf_symbols),\n",
        "        'recommendations_generated': len(recommendations) if not recommendations.empty else 0,\n",
        "        'average_confidence': recommendations['confidence'].mean() if not recommendations.empty else 0,\n",
        "        'average_predicted_return': recommendations['predicted_return'].mean() if not recommendations.empty else 0,\n",
        "        'models_trained': predictor.classification_model is not None\n",
        "    }\n",
        "\n",
        "    print(\"FINAL SUMMARY REPORT:\")\n",
        "    print(f\"Analysis completed at: {summary['timestamp']}\")\n",
        "    print(f\"ETFs analyzed: {summary['total_etfs_analyzed']}\")\n",
        "    print(f\"Recommendations: {summary['recommendations_generated']}\")\n",
        "    if summary['recommendations_generated'] > 0:\n",
        "        print(f\"Avg confidence: {summary['average_confidence']:.1%}\")\n",
        "        print(f\"Avg predicted return: {summary['average_predicted_return']:.1%}\")\n",
        "    print(f\"Models trained: {'Yes' if summary['models_trained'] else 'No'}\")\n",
        "\n",
        "    return summary\n",
        "\n",
        "# Export data and create final report\n",
        "export_recommendations_to_csv()\n",
        "save_models()\n",
        "final_summary = create_summary_report()"
      ],
      "metadata": {
        "id": "KZW6TCVRDZ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 21: Analyze and Improve Recommendations\n",
        "def analyze_recommendation_criteria():\n",
        "    \"\"\"Analyze why we're getting few recommendations and how to improve\"\"\"\n",
        "    print(\"ANALYZING RECOMMENDATION CRITERIA...\")\n",
        "\n",
        "    # Check all predictions (not just buy signals)\n",
        "    all_predictions = []\n",
        "\n",
        "    print(\"\\n Checking predictions for all ETFs:\")\n",
        "    for symbol in data_manager.etf_symbols[:15]:  # Check first 15 ETFs\n",
        "        try:\n",
        "            prediction = predictor.predict_etf_signals(symbol)\n",
        "            if prediction is not None and not prediction.empty:\n",
        "                latest = prediction.iloc[-1]\n",
        "                all_predictions.append({\n",
        "                    'symbol': symbol,\n",
        "                    'predicted_return': latest['predicted_return'],\n",
        "                    'confidence': latest['confidence'],\n",
        "                    'buy_signal': latest['buy_signal'],\n",
        "                    'current_price': latest['current_price']\n",
        "                })\n",
        "                status = \"✅ BUY\" if latest['buy_signal'] == 1 else \"⚠️ HOLD\"\n",
        "                print(f\"{symbol}: {latest['predicted_return']:.1%} return, {latest['confidence']:.1%} conf, {status}\")\n",
        "        except Exception as e:\n",
        "            print(f\"{symbol}: Error - {str(e)[:50]}...\")\n",
        "\n",
        "    if all_predictions:\n",
        "        pred_df = pd.DataFrame(all_predictions)\n",
        "\n",
        "        print(f\"\\n PREDICTION SUMMARY:\")\n",
        "        print(f\"Total predictions: {len(pred_df)}\")\n",
        "        print(f\"Buy signals: {(pred_df['buy_signal'] == 1).sum()}\")\n",
        "        print(f\"Hold signals: {(pred_df['buy_signal'] == 0).sum()}\")\n",
        "        print(f\"Average return: {pred_df['predicted_return'].mean():.1%}\")\n",
        "        print(f\"Max return: {pred_df['predicted_return'].max():.1%}\")\n",
        "        print(f\"Min return: {pred_df['predicted_return'].min():.1%}\")\n",
        "        print(f\"Average confidence: {pred_df['confidence'].mean():.1%}\")\n",
        "\n",
        "        # Show distribution\n",
        "        print(f\"\\n RETURN DISTRIBUTION:\")\n",
        "        bins = [-0.05, -0.02, 0, 0.01, 0.02, 0.05, 1.0]\n",
        "        labels = ['< -2%', '-2% to 0%', '0% to 1%', '1% to 2%', '2% to 5%', '> 5%']\n",
        "        pred_df['return_bin'] = pd.cut(pred_df['predicted_return'], bins=bins, labels=labels)\n",
        "        print(pred_df['return_bin'].value_counts().sort_index())\n",
        "\n",
        "        return pred_df\n",
        "    else:\n",
        "        print(\"No predictions generated\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def create_relaxed_recommendations(confidence_threshold=0.5, return_threshold=0.005):\n",
        "    \"\"\"Create recommendations with relaxed criteria\"\"\"\n",
        "    print(f\"\\n CREATING RELAXED RECOMMENDATIONS:\")\n",
        "    print(f\"Confidence threshold: {confidence_threshold:.1%}\")\n",
        "    print(f\"Return threshold: {return_threshold:.1%}\")\n",
        "\n",
        "    relaxed_recs = []\n",
        "\n",
        "    for symbol in data_manager.etf_symbols[:15]:\n",
        "        try:\n",
        "            prediction = predictor.predict_etf_signals(symbol)\n",
        "            if prediction is not None and not prediction.empty:\n",
        "                latest = prediction.iloc[-1]\n",
        "\n",
        "                # Relaxed criteria: confidence > 50% AND return > 0.5%\n",
        "                if (latest['confidence'] > confidence_threshold and\n",
        "                    latest['predicted_return'] > return_threshold):\n",
        "\n",
        "                    relaxed_recs.append({\n",
        "                        'symbol': symbol,\n",
        "                        'confidence': latest['confidence'],\n",
        "                        'predicted_return': latest['predicted_return'],\n",
        "                        'current_price': latest['current_price'],\n",
        "                        'buy_signal': 1  # Force buy signal for relaxed criteria\n",
        "                    })\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    relaxed_df = pd.DataFrame(relaxed_recs)\n",
        "\n",
        "    if not relaxed_df.empty:\n",
        "        # Sort by confidence * predicted_return (combined score)\n",
        "        relaxed_df['score'] = relaxed_df['confidence'] * relaxed_df['predicted_return']\n",
        "        relaxed_df = relaxed_df.sort_values('score', ascending=False)\n",
        "\n",
        "        print(f\"Found {len(relaxed_df)} recommendations with relaxed criteria:\")\n",
        "\n",
        "        # Format for display\n",
        "        display_df = relaxed_df.copy()\n",
        "        display_df['confidence'] = display_df['confidence'].apply(lambda x: f\"{x:.1%}\")\n",
        "        display_df['predicted_return'] = display_df['predicted_return'].apply(lambda x: f\"{x:.1%}\")\n",
        "        display_df['current_price'] = display_df['current_price'].apply(lambda x: f\"${x:.2f}\")\n",
        "        display_df['score'] = display_df['score'].apply(lambda x: f\"{x:.4f}\")\n",
        "\n",
        "        display(display_df[['symbol', 'confidence', 'predicted_return', 'current_price', 'score']].head(10))\n",
        "\n",
        "        return relaxed_df\n",
        "    else:\n",
        "        print(\"No recommendations even with relaxed criteria\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def improve_model_sensitivity():\n",
        "    \"\"\"Suggest ways to improve model sensitivity\"\"\"\n",
        "    print(f\"\\n SUGGESTIONS TO IMPROVE RECOMMENDATIONS:\")\n",
        "    print(f\"1. **Lower Buy Signal Threshold**: Current threshold is 2% return\")\n",
        "    print(f\"   - Try 1% or 1.5% for more signals\")\n",
        "    print(f\"   - Modify in FeatureEngineer.calculate_technical_indicators()\")\n",
        "    print(f\"\")\n",
        "    print(f\"2. **Use Confidence Scoring**: Instead of binary buy/sell\")\n",
        "    print(f\"   - Rank by confidence × predicted_return\")\n",
        "    print(f\"   - Take top N regardless of threshold\")\n",
        "    print(f\"\")\n",
        "    print(f\"3. **Market Regime Detection**: Adjust thresholds based on market conditions\")\n",
        "    print(f\"   - Bull market: higher thresholds\")\n",
        "    print(f\"   - Bear market: lower thresholds\")\n",
        "    print(f\"\")\n",
        "    print(f\"4. **Ensemble Approach**: Combine multiple models\")\n",
        "    print(f\"   - Short-term (5-day) and long-term (20-day) models\")\n",
        "    print(f\"   - Different risk profiles\")\n",
        "\n",
        "# Run the analysis\n",
        "prediction_analysis = analyze_recommendation_criteria()\n",
        "relaxed_recommendations = create_relaxed_recommendations()\n",
        "improve_model_sensitivity()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "wVrKB2LTDfFl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}